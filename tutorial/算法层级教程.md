# MiniMind ç®—æ³•å±‚çº§ Tutorial

> é¢å‘å¤§æ¨¡å‹ç®—æ³•å²—é¢è¯•çš„ç³»ç»Ÿæ€§çŸ¥è¯†æ•´ç†

## ç›®å½•

1. [é¡¹ç›®æ¦‚è¿°ä¸æ¶æ„æ€»è§ˆ](#1-é¡¹ç›®æ¦‚è¿°ä¸æ¶æ„æ€»è§ˆ)
2. [æ¨¡å‹æ¶æ„è¯¦è§£](#2-æ¨¡å‹æ¶æ„è¯¦è§£)
3. [é¢„è®­ç»ƒä¸ç›‘ç£å¾®è°ƒ](#3-é¢„è®­ç»ƒä¸ç›‘ç£å¾®è°ƒ)
4. [å¯¹é½ç®—æ³•è¯¦è§£](#4-å¯¹é½ç®—æ³•è¯¦è§£)
5. [çŸ¥è¯†è’¸é¦ç®—æ³•](#5-çŸ¥è¯†è’¸é¦ç®—æ³•)
6. [é¢è¯•é«˜é¢‘é—®é¢˜æ±‡æ€»](#6-é¢è¯•é«˜é¢‘é—®é¢˜æ±‡æ€»)
7. [æ ¸å¿ƒä»£ç æ·±åº¦è§£æ](#7-æ ¸å¿ƒä»£ç æ·±åº¦è§£æ)

---

## 1. é¡¹ç›®æ¦‚è¿°ä¸æ¶æ„æ€»è§ˆ

### 1.1 MiniMind æ˜¯ä»€ä¹ˆï¼Ÿ

MiniMind æ˜¯ä¸€ä¸ªæç®€å¤§è¯­è¨€æ¨¡å‹å¼€æºé¡¹ç›®ï¼Œç‰¹ç‚¹å¦‚ä¸‹ï¼š

- **æè½»é‡çº§**ï¼šæœ€å°æ¨¡å‹ä»… 25.8M å‚æ•°ï¼ˆGPT-3 çš„ 1/7000ï¼‰
- **ä½æˆæœ¬**ï¼šä»…éœ€ 3 å…ƒäººæ°‘å¸ + 2 å°æ—¶å³å¯è®­ç»ƒå®Œæˆ
- **å…¨æµç¨‹å¼€æº**ï¼šåŒ…å«é¢„è®­ç»ƒã€SFTã€LoRAã€DPOã€PPO/GRPO/SPO ç­‰å®Œæ•´ç®—æ³•
- **PyTorch åŸç”Ÿé‡æ„**ï¼šä¸ä¾èµ–ç¬¬ä¸‰æ–¹æŠ½è±¡æ¥å£ï¼Œä»é›¶å®ç°æ ¸å¿ƒç®—æ³•

### 1.2 æ ¸å¿ƒèƒ½åŠ›

```mermaid
---
config:
  theme: base
  themeVariables:
    primaryColor: "#e8f4f8"
    primaryBorderColor: "#2d6a7c"
    primaryTextColor: "#1a3a42"
    secondaryColor: "#f5f0e8"
    tertiaryColor: "#f0f5e8"
    lineColor: "#4a6670"
    fontFamily: "Georgia, serif"
    fontSize: "14px"
---
graph TD
    A((<b>MiniMind<br/>é¡¹ç›®</b>)) --> B[<b>æ¨¡å‹æ¶æ„</b><br/>Model Architecture]
    A --> C[<b>è®­ç»ƒç®—æ³•</b><br/>Training Algorithms]
    A --> D[<b>å·¥ç¨‹å®è·µ</b><br/>Engineering]
    
    B --> B1[ğŸ“¦ Transformer]
    B --> B2[ğŸ“ RoPE ä½ç½®ç¼–ç ]
    B --> B3[ğŸ”€ GQA æ³¨æ„åŠ›]
    B --> B4[ğŸ§© MoE æ··åˆä¸“å®¶]
    
    C --> C1[ğŸš€ é¢„è®­ç»ƒ]
    C --> C2[ğŸ¯ SFT å¾®è°ƒ]
    C --> C3[âš–ï¸ å¯¹é½ç®—æ³•]
    C --> C4[ğŸ“š çŸ¥è¯†è’¸é¦]
    
    D --> D1[âš¡ Flash Attention]
    D --> D2[ğŸ”¢ æ··åˆç²¾åº¦è®­ç»ƒ]
    D --> D3[ğŸŒ åˆ†å¸ƒå¼è®­ç»ƒ]
    D --> D4[ğŸ’¾ æ£€æŸ¥ç‚¹æ¢å¤]
    
    style A fill:#3d5a80 stroke:#293241 stroke-width:3px
    style B fill:#98c1d9 stroke:#293241 stroke-width:2px
    style C fill:#98c1d9 stroke:#293241 stroke-width:2px
    style D fill:#98c1d9 stroke:#293241 stroke-width:2px
    style B1 fill:#e0fbfc stroke:#2d6a7c stroke-width:1px
    style B2 fill:#e0fbfc stroke:#2d6a7c stroke-width:1px
    style B3 fill:#e0fbfc stroke:#2d6a7c stroke-width:1px
    style B4 fill:#e0fbfc stroke:#2d6a7c stroke-width:1px
    style C1 fill:#fcf6bd stroke:#d0a04b stroke-width:1px
    style C2 fill:#fcf6bd stroke:#d0a04b stroke-width:1px
    style C3 fill:#fcf6bd stroke:#d0a04b stroke-width:1px
    style C4 fill:#fcf6bd stroke:#d0a04b stroke-width:1px
    style D1 fill:#d4e09b stroke:#6a994e stroke-width:1px
    style D2 fill:#d4e09b stroke:#6a994e stroke-width:1px
    style D3 fill:#d4e09b stroke:#6a994e stroke-width:1px
    style D4 fill:#d4e09b stroke:#6a994e stroke-width:1px
```

### 1.3 å®Œæ•´è®­ç»ƒæµç¨‹

```mermaid
---
config:
  theme: base
  themeVariables:
    primaryColor: "#f8f9fa"
    primaryBorderColor: "#495057"
    lineColor: "#6c757d"
    fontFamily: "Georgia, serif"
---
flowchart LR
    A[ğŸ“<b>åŸå§‹æ•°æ®</b>] --> B[ğŸ”¤ åˆ†è¯å™¨è®­ç»ƒ]
    B --> C[ğŸš€ <b>é¢„è®­ç»ƒ</b><br/>Pretrain]
    C --> D[ğŸ¯ <b>SFT å¾®è°ƒ</b><br/>Supervised Fine-tuning]
    D --> E{ğŸ¤” å¯¹é½è®­ç»ƒ<br/>Alignment}
    E -->|åå¥½æ•°æ®| F[ğŸ“Š DPO<br/>Direct Preference<br/>Optimization]
    E -->|å¥–åŠ±æ¨¡å‹| G[ğŸ® PPO<br/>Proximal Policy<br/>Optimization]
    E -->|ç»„å†…å¥–åŠ±| H[ğŸ“ˆ GRPO<br/>Group Relative<br/>Policy Optimization]
    E -->|è‡ªå¯¹å¼ˆ| I[ğŸ² SPO<br/>Self-Play<br/>Optimization]
    
    style C fill:#d0f4de stroke:#2d6a4f stroke-width:3px
    style D fill:#a9def9 stroke:#1d3557 stroke-width:3px
    style E fill:#f4d35e stroke:#e07a5f stroke-width:2px
    style F fill:#e4c1f9 stroke:#7b2cbf stroke-width:2px
    style G fill:#ff99c8 stroke:#c9184a stroke-width:2px
    style H fill:#ffd6a5 stroke:#f77f00 stroke-width:2px
    style I fill:#9bf6ff stroke:#0077b6 stroke-width:2px
```

---

## 2. æ¨¡å‹æ¶æ„è¯¦è§£

### 2.1 æ•´ä½“æ¶æ„

```mermaid
---
config:
  theme: base
  themeVariables:
    primaryColor: "#e8f4f8"
    primaryBorderColor: "#2d6a7c"
    fontFamily: "Georgia, serif"
---
graph TB
    subgraph "MiniMindForCausalLM ä¸»æ¨¡å‹"
        direction TB
        A[ğŸ”¤ Input Tokens] --> B[ğŸ“¥ embed_tokens<br/>è¯åµŒå…¥å±‚]
        B --> C[ğŸ”» Dropout]
        C --> D[ğŸ“¦ MiniMindBlock Ã— 8<br/>Transformer å±‚]
        D --> E[ğŸ“ RMSNorm<br/>è¾“å‡ºå½’ä¸€åŒ–]
        E --> F[ğŸ¯ lm_head<br/>è¯­è¨€æ¨¡å‹å¤´]
        F --> G[ğŸ“Š Output logits<br/>è¾“å‡ºæ¦‚ç‡]
    end
    
    subgraph "MiniMindBlock å•å±‚ç»“æ„"
        direction LR
        H[ğŸ“¥ Input] --> I[ğŸ“ RMSNormâ‚]
        I --> J[ğŸ‘ï¸ Attention<br/>æ³¨æ„åŠ›æœºåˆ¶]
        J --> K[ğŸ”— æ®‹å·®è¿æ¥]
        K --> L[ğŸ“ RMSNormâ‚‚]
        L --> M[ğŸ§  MLP / MoE<br/>å‰é¦ˆç½‘ç»œ]
        M --> N[ğŸ”— æ®‹å·®è¿æ¥]
        N --> O[ğŸ“¤ Output]
    end
    
    style A fill:#e3f2fd stroke:#1565c0 stroke-width:2px
    style B fill:#bbdefb stroke:#1565c0 stroke-width:2px
    style C fill:#90caf9 stroke:#1565c0 stroke-width:2px
    style D fill:#64b5f6 stroke:#0d47a1 stroke-width:3px
    style E fill:#42a5f5 stroke:#0d47a1 stroke-width:2px
    style F fill:#2196f3 stroke:#0d47a1 stroke-width:2px
    style G fill:#1e88e5 stroke:#0d47a1 stroke-width:2px
    style H fill:#f3e5f5 stroke:#7b1fa2 stroke-width:1px
    style I fill:#e1bee7 stroke:#7b1fa2 stroke-width:1px
    style J fill:#ce93d8 stroke:#7b1fa2 stroke-width:2px
    style K fill:#ba68c8 stroke:#7b1fa2 stroke-width:1px
    style L fill:#ab47bc stroke:#7b1fa2 stroke-width:1px
    style M fill:#9c27b0 stroke:#6a1b9a stroke-width:2px
    style N fill:#8e24aa stroke:#6a1b9a stroke-width:1px
    style O fill:#7b1fa2 stroke:#6a1b9a stroke-width:1px
```

### 2.2 å…³é”®æŠ€æœ¯ç»„ä»¶

#### 2.2.1 MiniMindConfig é…ç½®ç±»

```python
class MiniMindConfig:
    def __init__(
        self,
        dropout: float = 0.0,
        hidden_size: int = 512,      # éšè—å±‚ç»´åº¦
        num_attention_heads: int = 8,  # æ³¨æ„åŠ›å¤´æ•°
        num_hidden_layers: int = 8,    # Transformer å±‚æ•°
        num_key_value_heads: int = 2,  # KV å¤´æ•°ï¼ˆGQA å…³é”®ï¼‰
        vocab_size: int = 6400,        # è¯è¡¨å¤§å°
        max_position_embeddings: int = 32768,  # æœ€å¤§ä½ç½®
        rope_theta: int = 1000000.0,   # RoPE åŸºç¡€é¢‘ç‡
        inference_rope_scaling: bool = False,  # YaRN å¤–æ¨
        flash_attn: bool = True,       # Flash Attention
        use_moe: bool = False,         # MoE å¼€å…³
        num_experts_per_tok: int = 2,  # æ¯ token æ¿€æ´»ä¸“å®¶æ•°
        n_routed_experts: int = 4,     # æ€»ä¸“å®¶æ•°
    ):
```

#### 2.2.2 RMSNorm vs LayerNorm

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
graph TD
    subgraph "ğŸ”¹ LayerNorm ä¼ ç»Ÿå½’ä¸€åŒ–"["<b>LayerNorm</b><br/>ä¼ ç»Ÿå½’ä¸€åŒ–"]
        direction TB
        A1["ğŸ“¥ x"] --> A2["<b>Î¼</b><br/>è®¡ç®—å‡å€¼"]
        A2 --> A3["<b>ÏƒÂ²</b><br/>è®¡ç®—æ–¹å·®"]
        A3 --> A4["x' = (x-Î¼)/âˆš(ÏƒÂ²+Îµ)"]
        A4 --> A5["y = Î³âŠ™x' + Î²<br/>ç¼©æ”¾+åç§»"]
    end
    
    subgraph "ğŸ”¸ RMSNorm è½»é‡å½’ä¸€åŒ–"["<b>RMSNorm</b><br/>è½»é‡å½’ä¸€åŒ–"]
        direction TB
        B1["ğŸ“¥ x"] --> B2["<b>RMS</b><br/>è®¡ç®—å‡æ–¹æ ¹"]
        B2 --> B3["y = Î³âŠ™x/RMS<br/>ä»…ç¼©æ”¾"]
    end
    
    style A1 fill:#fff3e0 stroke:#e65100 stroke-width:2px
    style A2 fill:#ffe0b2 stroke:#e65100 stroke-width:1px
    style A3 fill:#ffcc80 stroke:#e65100 stroke-width:1px
    style A4 fill:#ffb74d stroke:#e65100 stroke-width:1px
    style A5 fill:#ffa726 stroke:#e65100 stroke-width:2px
    
    style B1 fill:#e8f5e9 stroke:#2e7d32 stroke-width:2px
    style B2 fill:#c8e6c9 stroke:#2e7d32 stroke-width:1px
    style B3 fill:#a5d6a7 stroke:#2e7d32 stroke-width:2px
```

**RMSNorm ä»£ç å®ç°**ï¼š
```python
class RMSNorm(nn.Module):
    def __init__(self, dim: int, eps: float = 1e-5):
        super().__init__()
        self.eps = eps
        self.weight = nn.Parameter(torch.ones(dim))
    
    def forward(self, x):
        return self.weight * torch.rsqrt(
            x.pow(2).mean(-1, keepdim=True) + self.eps
        ).type_as(x)
```

**é¢è¯•è¦ç‚¹**ï¼š
- RMSNormå…¶æ ¸å¿ƒå‡è®¾æ˜¯ï¼šé‡æ–°å¹³ç§»ï¼ˆRe-centeringï¼Œå³å‡å»å‡å€¼ï¼‰å¯¹æ¨¡å‹æ€§èƒ½çš„è´¡çŒ®å¾ˆå°ï¼Œè€Œé‡æ–°ç¼©æ”¾ï¼ˆRe-scalingï¼‰æ‰æ˜¯å…³é”®ã€‚
- RMSNorm æ¯” LayerNorm æ›´è½»é‡ï¼ˆå°‘ 2 ä¸ªå¯å­¦ä¹ å‚æ•°ï¼šÎ² å’Œ varï¼‰
- åœ¨ FP16/BF16 ç­‰åŠç²¾åº¦è®­ç»ƒä¸­ï¼Œå‡æ³•æ“ä½œæœ‰æ—¶ä¼šå¸¦æ¥æ•°å€¼ä¸ç¨³å®šæ€§ã€‚RMSNorm çš„é€»è¾‘æ›´ç®€å•ï¼Œæ›´é€‚åˆç°ä»£æ˜¾å¡çš„å¹¶è¡ŒåŠ é€Ÿï¼ˆFused Kernelï¼‰ã€‚
- ä»…éœ€è®¡ç®— RMSï¼ˆå‡æ–¹æ ¹ï¼‰ï¼Œä¸éœ€è¦è®¡ç®—å‡å€¼
- LLaMA ç³»åˆ— (Meta),Gemma (Google),Mistral / Mixtral,DeepSeek ç³»åˆ—,Qwenç³»åˆ—

### 2.3 RoPE ä½ç½®ç¼–ç 

#### 2.3.1 RoPE æ ¸å¿ƒåŸç†

RoPEï¼ˆRotary Position Embeddingï¼‰å°†ç»å¯¹ä½ç½®ä¿¡æ¯ç¼–ç ä¸ºæ—‹è½¬çŸ©é˜µï¼š

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
graph LR
    subgraph "ğŸ”„ RoPE æ ¸å¿ƒæ€æƒ³"
        A["ğŸ“Š Q/K å‘é‡"] -->|"æ—‹è½¬å˜æ¢"| B["ğŸ”¢ ç¼–ç ä½ç½®"]
        B -->|"å†…ç§¯"| C["ğŸ“ ç›¸å¯¹ä½ç½®<br/>ä¿ç•™"]
    end
    
    style A fill:#e3f2fd stroke:#1565c0 stroke-width:2px
    style B fill:#bbdefb stroke:#1565c0 stroke-width:2px
    style C fill:#90caf9 stroke:#1565c0 stroke-width:2px
```

**æ•°å­¦å…¬å¼**ï¼š
$$RoPE(q_m, k_n) = Re[(q_m e^{imÎ¸}) (k_n e^{inÎ¸})^*]$$

**æ ¸å¿ƒæ€æƒ³**:
åœ¨å¤å¹³é¢ä¸Šï¼Œé€šè¿‡æ—‹è½¬ä¸€ä¸ªå‘é‡æ¥æ³¨å…¥ä½ç½®ä¿¡æ¯ã€‚
- æ¯ä¸ª token æ ¹æ®å…¶æ‰€åœ¨ä½ç½® $m$ï¼Œåœ¨ç‰¹å¾å‘é‡ä¸Šæ–½åŠ ä¸€ä¸ªç‰¹å®šçš„æ—‹è½¬è§’åº¦
- å½“ä¸¤ä¸ªå‘é‡ $q$ï¼ˆä½ç½® $m$ï¼‰å’Œ $k$ï¼ˆä½ç½® $n$ï¼‰åšç‚¹ç§¯æ—¶ï¼Œå…¶ç»“æœåªå–å†³äºå®ƒä»¬ä¹‹é—´çš„ç›¸å¯¹å¤¹è§’ï¼ˆå³ $m-n$ï¼‰ï¼Œè€Œä¸ç»å¯¹æ—‹è½¬äº†å¤šå°‘æ— å…³ã€‚

#### 2.3.2 ä»£ç å®ç°

```python
def precompute_freqs_cis(dim: int, end: int, rope_base: float = 1e6):
    # è®¡ç®—é¢‘ç‡å‘é‡
    freqs = 1.0 / (rope_base ** (torch.arange(0, dim, 2).float() / dim))
    
    # ç”Ÿæˆä½ç½®ç´¢å¼•
    t = torch.arange(end, device=freqs.device)
    freqs = torch.outer(t, freqs)
    
    # åˆå¹¶ cos å’Œ sin
    freqs_cos = torch.cat([torch.cos(freqs), torch.cos(freqs)], dim=-1)
    freqs_sin = torch.cat([torch.sin(freqs), torch.sin(freqs)], dim=-1)
    
    return freqs_cos, freqs_sin

def apply_rotary_pos_emb(q, k, cos, sin):
    def rotate_half(x):
        # æ—‹è½¬æ“ä½œï¼š[-xâ‚‚, xâ‚]
        return torch.cat((-x[..., x.shape[-1] // 2:], 
                          x[..., : x.shape[-1] // 2]), dim=-1)
    
    q_embed = q * cos.unsqueeze(unsqueeze_dim) + rotate_half(q) * sin.unsqueeze(unsqueeze_dim)
    k_embed = k * cos.unsqueeze(unsqueeze_dim) + rotate_half(k) * sin.unsqueeze(unsqueeze_dim)
    return q_embed, k_embed
```

**ä»£ç è§£è¯»**ï¼š
- ç”Ÿæˆä¸€å¼ æ—‹è½¬å‚æ•°è¡¨ï¼Œé¢‘ç‡ä¸åŒè¡¨ç¤ºä¸åŒç»´åº¦çš„æ—‹è½¬é€Ÿåº¦æ˜¯ä¸ä¸€æ ·çš„ã€‚
- å°†ä½ç½®ç´¢å¼• $t$ (0, 1, 2...) ä¸é¢‘ç‡ç›¸ä¹˜ã€‚å¾—åˆ°ä¸€ä¸ªçŸ©é˜µï¼Œæ¯ä¸€è¡Œä»£è¡¨ä¸€ä¸ªä½ç½®ï¼Œæ¯ä¸€åˆ—å¯¹åº”ä¸€ä¸ªç»´åº¦çš„æ—‹è½¬è§’åº¦ $\theta = m \cdot \theta_i$ã€‚
- æ‰§è¡ŒäºŒç»´å¹³é¢çš„æ—‹è½¬

#### 2.3.3 YaRN ä½ç½®ç¼–ç å¤–æ¨

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
flowchart TD
    A[ğŸ“ <b>åŸå§‹ä½ç½®ç¼–ç </b>] --> B{âš™ï¸ rope_scaling<br/>æ˜¯å¦é…ç½®?}
    B -->|No â›”| C[âœ… ç›´æ¥ä½¿ç”¨]
    B -->|Yes âœ…| D["ğŸ”§ çº¿æ€§æ’å€¼<br/>ramp å‡½æ•°"]
    D --> E["ğŸ“Š freqs Ã—<br/>interpolate_factor"]
    E --> F[ğŸš€ <b>æ”¯æŒæ›´é•¿ä¸Šä¸‹æ–‡</b><br/>4Ã— é•¿åº¦æ‰©å±•]
    
    style A fill:#e8f5e9 stroke:#2e7d32 stroke-width:2px
    style B fill:#fff3e0 stroke:#e65100 stroke-width:2px
    style C fill:#c8e6c9 stroke:#2e7d32 stroke-width:1px
    style D fill:#fff8e1 stroke:#ff8f00 stroke-width:1px
    style E fill:#ffecb3 stroke:#ff8f00 stroke-width:1px
    style F fill:#d4e09b stroke:#388e3c stroke-width:3px
```

```python
if rope_scaling is not None:
    orig_max = rope_scaling["original_max_position_embeddings"]
    factor = rope_scaling["factor"]
    
    if end / orig_max > 1.0:
        # çº¿æ€§æ’å€¼ ramp
        ramp = torch.clamp(
            (torch.arange(dim // 2) - low) / max(high - low, 0.001), 
            0, 1
        )
        freqs = freqs * (1 - ramp + ramp / factor)
```

**é¢è¯•è¦ç‚¹**ï¼š
- ç»å¯¹ä½ç½®ç¼–ç å¤–æ¨æ€§å·®ï¼Œç›¸å¯¹ä½ç½®ç¼–ç è®¡ç®—å¼€é”€å¤§ã€‚
- RoPE çš„ä¼˜åŠ¿ï¼šå¤–æ¨æ€§å¥½ã€è®¡ç®—é«˜æ•ˆã€å¯å¤–æ¨æ— é™é•¿åº¦
- YaRN æ ¸å¿ƒæ€æƒ³ï¼šä½é¢‘ä½ç½®çº¿æ€§æ’å€¼ï¼Œé«˜é¢‘ä¿æŒåŸæ ·
- MiniMind æ”¯æŒ 4 å€é•¿åº¦æ‰©å±•

### 2.4 Grouped Query Attention (GQA)

#### 2.4.1 æ³¨æ„åŠ›æœºåˆ¶æ¼”è¿›

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
graph LR
    MHA["<b>MHA</b><br/>Multi-Head<br/>Attention<br/>Q=K=V=32å¤´"] -->|"GQA<br/>æ¼”è¿›"| GQA["<b>GQA</b><br/>Grouped Query<br/>Q=32å¤´, KV=4å¤´<br/>MiniMindé‡‡ç”¨"]
    GQA -->|"ç»§ç»­æ¼”è¿›"| MQA["<b>MQA</b><br/>Multi-Query<br/>Q=32å¤´, KV=1å¤´"]
    
    style MHA fill:#ffecb3 stroke:#e65100 stroke-width:2px
    style GQA fill:#a5d6a7 stroke:#2e7d32 stroke-width:3px
    style MQA fill:#bbdefb stroke:#1565c0 stroke-width:2px
```

#### 2.4.2 GQA ä»£ç å®ç°

```python
class Attention(nn.Module):
    def __init__(self, args: MiniMindConfig):
        self.num_key_value_heads = args.num_key_value_heads  # KV å¤´æ•°
        self.n_local_heads = args.num_attention_heads        # Q å¤´æ•°
        self.n_local_kv_heads = self.num_key_value_heads     # KV å¤´æ•°
        self.n_rep = self.n_local_heads // self.n_local_kv_heads  # å¤åˆ¶å€æ•°
        
        self.head_dim = args.hidden_size // args.num_attention_heads
        
        # Q, K, V ç‹¬ç«‹æŠ•å½±
        self.q_proj = nn.Linear(args.hidden_size, args.num_attention_heads * self.head_dim)
        self.k_proj = nn.Linear(args.hidden_size, self.num_key_value_heads * self.head_dim)
        self.v_proj = nn.Linear(args.hidden_size, self.num_key_value_heads * self.head_dim)

def repeat_kv(x: torch.Tensor, n_rep: int) -> torch.Tensor:
    """å°† KV å¤´å¤åˆ¶ n_rep æ¬¡ä»¥åŒ¹é… Q å¤´æ•°é‡"""
    bs, slen, num_key_value_heads, head_dim = x.shape
    return (
        x[:, :, :, None, :].expand(bs, slen, num_key_value_heads, n_rep, head_dim)
        .reshape(bs, slen, num_key_value_heads * n_rep, head_dim)
    )
```

**é¢è¯•è¦ç‚¹**ï¼š
- GQA ä¼˜åŠ¿ï¼š
  -  åœ¨æ¨ç†ï¼ˆInferenceï¼‰æ—¶ï¼Œæˆ‘ä»¬éœ€è¦ç¼“å­˜ä¹‹å‰çš„ $KV$ å€¼ï¼ˆKV Cacheï¼‰ã€‚å¦‚æœ $KV$ å¤´æ•°å‡å°‘åˆ° 1/4ï¼ŒKV Cache å ç”¨çš„æ˜¾å­˜ç›´æ¥å‡å°‘ 75%ã€‚è¿™å¯¹äºé•¿æ–‡æœ¬ç”Ÿæˆè‡³å…³é‡è¦ã€‚
  -  æ¨ç†æ—¶çš„ç“¶é¢ˆå¾€å¾€ä¸åœ¨è®¡ç®—é‡ï¼Œè€Œåœ¨ä»æ˜¾å­˜è¯»å– KV Cache çš„é€Ÿåº¦ã€‚$KV$ å˜å°‘äº†ï¼Œæ•°æ®æ¬è¿å°±å˜å¿«äº†ï¼Œæ¨ç†é€Ÿåº¦ï¼ˆTokens/sï¼‰å¤§å¹…æå‡ã€‚
- Qwen2ã€Llama3 é‡‡ç”¨ GQA
- MiniMind é»˜è®¤é…ç½®ï¼šQ=8 å¤´ï¼ŒKV=2 å¤´ï¼ˆ4 å€å‹ç¼©ï¼‰

### 2.5 Flash Attention

#### 2.5.1 ä¼ ç»Ÿ Attention vs Flash Attention

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
flowchart LR
    subgraph "âš ï¸ ä¼ ç»Ÿ Attention" ["<b>ä¼ ç»Ÿ Attention</b><br/>O(NÂ²) æ˜¾å­˜"]
        direction TB
        A1[ğŸ“Š QÃ—Káµ€] --> A2[ğŸ§® Softmax]
        A2 --> A3[ğŸ“Š V åŠ æƒ]
        A3 --> A4[ğŸ“¤ è¾“å‡º]
    end
    
    subgraph "âœ… Flash Attention" ["<b>Flash Attention</b><br/>O(N) æ˜¾å­˜"]
        direction TB
        B1[ğŸ“¦ åˆ†å—è®¡ç®—] --> B2["âš¡ åœ¨çº¿<br/>Softmax"]
        B2 --> B3[ğŸ“Š ç´¯åŠ è¾“å‡º]
        B3 --> B4[ğŸš€ é«˜é€Ÿ]
    end
    
    style A1 fill:#ffcdd2 stroke:#c62828 stroke-width:2px
    style A2 fill:#ef9a9a stroke:#c62828 stroke-width:1px
    style A3 fill:#e57373 stroke:#c62828 stroke-width:1px
    style A4 fill:#ef5350 stroke:#c62828 stroke-width:2px
    
    style B1 fill:#c8e6c9 stroke:#2e7d32 stroke-width:2px
    style B2 fill:#a5d6a7 stroke:#2e7d32 stroke-width:1px
    style B3 fill:#81c784 stroke:#2e7d32 stroke-width:1px
    style B4 fill:#66bb6a stroke:#2e7d32 stroke-width:2px
```

```python
if self.flash and seq_len > 1:
    # Flash Attention åˆ©ç”¨ CUDA æ ¸å‡½æ•°
    output = F.scaled_dot_product_attention(
        xq, xk, xv,
        dropout_p=self.dropout if self.training else 0.0,
        is_causal=True  # å› æœæ©ç 
    )
else:
    # æ‰‹åŠ¨è®¡ç®—ï¼ˆå…¼å®¹æ€§æ–¹æ¡ˆï¼‰
    scores = (xq @ xk.transpose(-2, -1)) / math.sqrt(self.head_dim)
    scores = scores + torch.triu(
        torch.full((seq_len, seq_len), float("-inf")),
        diagonal=1
    ).unsqueeze(0).unsqueeze(0)
```

### 2.6 MoE æ··åˆä¸“å®¶æ¨¡å‹

#### 2.6.1 MoE æ¶æ„

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
graph TB
    A[ğŸ“¥ <b>è¾“å…¥ x</b>] --> B[<b>ğŸ§­ MoE Gate</b><br/>è·¯ç”±é—¨æ§]
    B --> C["ğŸ¯ <b>Top-2 è·¯ç”±</b><br/>é€‰æ‹©ä¸“å®¶"]
    
    subgraph "ğŸ—‚ï¸ <b>ä¸“å®¶æ± </b> Expert Pool" ["ğŸ—‚ï¸ <b>ä¸“å®¶æ± </b><br/>Expert Pool"]
        D[ğŸ‘¤ Expert 1]
        E[ğŸ‘¤ Expert 2]
        F[ğŸ‘¤ Expert 3]
        G[ğŸ‘¤ Expert 4]
    end
    
    C -->|"é€‰ä¸­ 1"| D
    C -->|"é€‰ä¸­ 2"| E
    
    D --> H["âš–ï¸ <b>åŠ æƒè¾“å‡º</b><br/>Weighted Sum"]
    E --> H
    
    H --> I[<b>ğŸ”— å…±äº«ä¸“å®¶</b><br/>Shared Experts]
    I --> J[ğŸ“¤ <b>æœ€ç»ˆè¾“å‡º</b>]
    
    style A fill:#e3f2fd stroke:#1565c0 stroke-width:2px
    style B fill:#fff9c4 stroke:#f9a825 stroke-width:2px
    style C fill:#c8e6c9 stroke:#2e7d32 stroke-width:2px
    style D fill:#f3e5f5 stroke:#7b1fa2 stroke-width:1px
    style E fill:#f3e5f5 stroke:#7b1fa2 stroke-width:1px
    style F fill:#f3e5f5 stroke:#7b1fa2 stroke-width:1px
    style G fill:#f3e5f5 stroke:#7b1fa2 stroke-width:1px
    style H fill:#ce93d8 stroke:#7b1fa2 stroke-width:2px
    style I fill:#fff3e0 stroke:#e65100 stroke-width:2px
    style J fill:#a5d6a7 stroke:#2e7d32 stroke-width:2px
```

#### 2.6.2 MoE Gate ä»£ç 

```python
class MoEGate(nn.Module):
    def forward(self, hidden_states):
        # 1. è®¡ç®—ä¸“å®¶è¯„åˆ†
        logits = F.linear(hidden_states, self.weight, None)
        scores = logits.softmax(dim=-1)
        
        # 2. Top-K é€‰æ‹©
        topk_weight, topk_idx = torch.topk(scores, k=self.top_k, dim=-1)
        
        # 3. æ ‡å‡†åŒ–æƒé‡
        if self.top_k > 1 and self.norm_topk_prob:
            denominator = topk_weight.sum(dim=-1, keepdim=True) + 1e-20
            topk_weight = topk_weight / denominator
        
        # 4. è¾…åŠ©æŸå¤±ï¼šè´Ÿè½½å‡è¡¡
        if self.training and self.alpha > 0.0:
            aux_loss = self._compute_aux_loss(topk_idx, scores)
        
        return topk_idx, topk_weight, aux_loss
    
    def _compute_aux_loss(self, topk_idx, scores):
        # è´Ÿè½½å‡è¡¡è¾…åŠ©æŸå¤±
        _, num_expert = topk_idx.shape
        expert_mask = F.one_hot(topk_idx, num_expert).float()
        expert_load = expert_mask.sum(dim=0) / expert_mask.sum(dim=1).unsqueeze(0)
        aux_loss = (expert_load ** 2).mean() * self.num_experts_per_tok
        return aux_loss
```

#### 2.6.3 MOE FeedForward ä»£ç 

```python
class MOEFeedForward(nn.Module):
    def forward(self, x):
        # 1. è·å–è·¯ç”±å†³ç­–
        topk_idx, topk_weight, aux_loss = self.gate(x)
        
        if self.training:
            # è®­ç»ƒæ—¶ï¼šscatter åˆå¹¶
            y = torch.zeros_like(x)
            for i, expert in enumerate(self.experts):
                y[flat_topk_idx == i] = expert(x[flat_topk_idx == i])
            y = (y.view(*topk_weight.shape, -1) * topk_weight.unsqueeze(-1)).sum(dim=1)
        else:
            # æ¨ç†æ—¶ï¼šæ’åºä¼˜åŒ–
            y = self.moe_infer(x, flat_topk_idx, topk_weight.view(-1, 1))
        
        # 2. å…±äº«ä¸“å®¶
        if self.config.n_shared_experts > 0:
            for expert in self.shared_experts:
                y = y + expert(identity)
        
        self.aux_loss = aux_loss
        return y
```

**é¢è¯•è¦ç‚¹**ï¼š
- MoE æ ¸å¿ƒæ€æƒ³ï¼šç¨€ç–æ¿€æ´»ï¼Œæ¯ä¸ª token åªæ¿€æ´»éƒ¨åˆ†ä¸“å®¶
- è´Ÿè½½å‡è¡¡æŸå¤±ï¼šé˜²æ­¢ä¸“å®¶å¡Œé™·
- å…±äº«ä¸“å®¶ï¼šæé«˜ä¸“å®¶é—´çŸ¥è¯†å…±äº«

---

## 3. é¢„è®­ç»ƒä¸ç›‘ç£å¾®è°ƒ

### 3.1 é¢„è®­ç»ƒ (Pretrain)

#### 3.1.1 ç›®æ ‡å‡½æ•°

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
flowchart LR
    A[ğŸ“¥ <b>è¾“å…¥åºåˆ—</b>] --> B[ğŸ”„ æ¨¡å‹å‰å‘]
    B --> C[ğŸ“Š Logits è¾“å‡º]
    C --> D["ğŸ¯ <b>Next Token</b><br/>é¢„æµ‹"]
    D --> E[ğŸ“‰ Cross Entropy<br/>æŸå¤±å‡½æ•°]
    
    subgraph "ğŸ”§ MiniMind é…ç½®"
        F["âš™ï¸ use_moe=True"] --> G["ğŸ“Š æ€»æŸå¤± =<br/>CE + aux_loss"]
    end
    
    E --> H[â¬…ï¸ åå‘ä¼ æ’­]
    H --> I[âœ… å‚æ•°æ›´æ–°]
    
    style A fill:#d0f4de stroke:#2e7d32 stroke-width:2px
    style B fill:#a9def9 stroke:#1d3557 stroke-width:2px
    style C fill:#e4c1f9 stroke:#7b2cbf stroke-width:2px
    style D fill:#fcf6bd stroke:#d0a04b stroke-width:2px
    style E fill:#ff99c8 stroke:#c9184a stroke-width:2px
    style F fill:#fff3e0 stroke:#e65100 stroke-width:1px
    style G fill:#ffe0b2 stroke:#e65100 stroke-width:2px
    style H fill:#bbdefb stroke:#1565c0 stroke-width:2px
    style I fill:#64b5f6 stroke:#0d47a1 stroke-width:2px
```

```python
def train_step(model, X, Y, loss_mask):
    # å‰å‘ä¼ æ’­
    res = model(X)
    logits = res.logits  # [B, seq_len, vocab_size]
    
    # è®¡ç®—æŸå¤±
    loss_fct = nn.CrossEntropyLoss(reduction='none')
    loss = loss_fct(logits.view(-1, logits.size(-1)), Y.view(-1))
    
    # æŸå¤±æ©ç 
    loss_mask_flat = loss_mask.view(-1)
    loss = torch.sum(loss * loss_mask_flat) / loss_mask_flat.sum()
    
    # MoE è¾…åŠ©æŸå¤±
    if lm_config.use_moe:
        loss += res.aux_loss
    
    return loss
```

#### 3.1.2 æ··åˆç²¾åº¦è®­ç»ƒ

```python
# è‡ªåŠ¨æ··åˆç²¾åº¦ (AMP)
dtype = torch.bfloat16 if args.dtype == "bfloat16" else torch.float16
autocast_ctx = torch.cuda.amp.autocast(dtype=dtype)

scaler = torch.cuda.amp.GradScaler(enabled=(args.dtype == 'float16'))

with autocast_ctx:
    loss = compute_loss()
    
scaler.scale(loss).backward()
scaler.unscale_(optimizer)
torch.nn.utils.clip_grad_norm_(model.parameters(), args.grad_clip)
scaler.step(optimizer)
scaler.update()
```

### 3.2 SFT ç›‘ç£å¾®è°ƒ

#### 3.2.1 æ•°æ®æ ¼å¼

```json
{
  "conversations": [
    {"role": "user", "content": "ä½ å¥½"},
    {"role": "assistant", "content": "ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ"}
  ]
}
```

#### 3.2.2 ChatML æ¨¡æ¿

```python
def _create_chat_prompt(self, conversations):
    prompt = ""
    for msg in conversations:
        if msg["role"] == "user":
            prompt += f"<|im_start|>user\n{msg['content']}<|im_end|>\n"
        elif msg["role"] == "assistant":
            prompt += f"<|im_start|>assistant\n{msg['content']}<|im_end|>\n"
    prompt += "<|im_start|>assistant"
    return prompt
```

#### 3.2.3 åŠ¨æ€æŸå¤±æ©ç 

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
flowchart LR
    A[ğŸ“¥ <b>è¾“å…¥åºåˆ—</b>] --> B{ğŸ” æ£€æµ‹ BOS<br/>æ ‡è®°?}
    B -->|å¦| A
    B -->|æ˜¯ âœ…| C["ğŸ“ æ ‡è®°å›å¤<br/>å¼€å§‹ä½ç½®"]
    C --> D[ğŸ”š æ‰¾åˆ° EOS<br/>æ ‡è®°]
    D --> E["âš™ï¸ è®¾ç½®<br/>loss_mask=1"]
    E --> F["ğŸ¯ åªè®¡ç®—å›å¤<br/>éƒ¨åˆ†æŸå¤±"]
    
    style A fill:#e8f5e9 stroke:#2e7d32 stroke-width:2px
    style B fill:#fff3e0 stroke:#e65100 stroke-width:2px
    style C fill:#c8e6c9 stroke:#2e7d32 stroke-width:1px
    style D fill:#a5d6a7 stroke:#2e7d32 stroke-width:1px
    style E fill:#81c784 stroke:#2e7d32 stroke-width:1px
    style F fill:#66bb6a stroke:#2e7d32 stroke-width:2px
```

```python
def _generate_loss_mask(self, input_ids):
    loss_mask = [0] * len(input_ids)
    i = 0
    while i < len(input_ids):
        if input_ids[i:i + len(self.bos_id)] == self.bos_id:
            start = i + len(self.bos_id)
            end = start
            while end < len(input_ids):
                if input_ids[end:end + len(self.eos_id)] == self.eos_id:
                    break
                end += 1
            # åªå¯¹ assistant å›å¤éƒ¨åˆ†è®¡ç®—æŸå¤±
            for j in range(start + 1, min(end + len(self.eos_id) + 1, self.max_length)):
                loss_mask[j] = 1
            i = end + len(self.eos_id)
        else:
            i += 1
    return loss_mask
```

---

## 4. å¯¹é½ç®—æ³•è¯¦è§£

### 4.1 å¯¹é½ç®—æ³•å…¨æ™¯

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
graph TD
    A[ğŸ¤– <b>RLHF</b><br/>å¼ºåŒ–å­¦ä¹ äººç±»åé¦ˆ] --> B[ğŸ“Š <b>DPO</b><br/>Direct Preference<br/>Optimization]
    A --> C[ğŸ® <b>PPO</b><br/>Proximal Policy<br/>Optimization]
    A --> D[ğŸ“ˆ <b>GRPO</b><br/>Group Relative<br/>Policy Optimization]
    A --> E[ğŸ² <b>SPO</b><br/>Self-Play<br/>Optimization]
    
    B --> B1["âœ… ç›´æ¥åå¥½<br/>æ— éœ€å¥–åŠ±æ¨¡å‹"]
    C --> C1["âš™ï¸ ç»å…¸PPO<br/>éœ€è¦Criticæ¨¡å‹"]
    D --> D1["ğŸ“Š ç»„ç›¸å¯¹å¥–åŠ±<br/>æ— éœ€Critic"]
    E --> E1["ğŸ”„ è‡ªé€‚åº”è°ƒæ•´<br/>æ— éœ€å¥–åŠ±æ¨¡å‹"]
    
    style A fill:#3d5a80 stroke:#293241 stroke-width:3px
    style B fill:#98c1d9 stroke:#293241 stroke-width:2px
    style C fill:#98c1d9 stroke:#293241 stroke-width:2px
    style D fill:#98c1d9 stroke:#293241 stroke-width:2px
    style E fill:#98c1d9 stroke:#293241 stroke-width:2px
    style B1 fill:#e4c1f9 stroke:#7b2cbf stroke-width:1px
    style C1 fill:#ff99c8 stroke:#c9184a stroke-width:1px
    style D1 fill:#ffd6a5 stroke:#f77f00 stroke-width:1px
    style E1 fill:#9bf6ff stroke:#0077b6 stroke-width:1px
```

### 4.2 DPO (Direct Preference Optimization)

#### 4.2.1 æ ¸å¿ƒæ€æƒ³

DPO é€šè¿‡ç›´æ¥ä¼˜åŒ–åå¥½æ•°æ®æ¥å¯¹é½æ¨¡å‹ï¼Œæ— éœ€æ˜¾å¼çš„å¥–åŠ±æ¨¡å‹ã€‚

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
flowchart LR
    subgraph "ğŸ“ Dataset"
        A["âœ… chosen<br/>å¥½å›ç­”"] -.->|"å¯¹æ¯”"| B["âŒ rejected<br/>å·®å›ç­”"]
    end
    
    B --> C["ğŸ¯ <b>Policy Model</b><br/>ç­–ç•¥æ¨¡å‹"]
    A --> C
    C --> D["ğŸ“Š <b>Reference Model</b><br/>å‚è€ƒæ¨¡å‹<br/>å†»ç»“"]
    D --> E["ğŸ“‰ DPO Loss<br/>å¯¹é½ä¼˜åŒ–"]
    
    style A fill:#c8e6c9 stroke:#2e7d32 stroke-width:2px
    style B fill:#ffcdd2 stroke:#c62828 stroke-width:2px
    style C fill:#a5d6a7 stroke:#2e7d32 stroke-width:2px
    style D fill:#bbdefb stroke:#1565c0 stroke-width:2px
    style E fill:#81c784 stroke:#2e7d32 stroke-width:2px
```

#### 4.2.2 DPO æŸå¤±å‡½æ•°

```python
def dpo_loss(ref_log_probs, policy_log_probs, mask, beta=0.1):
    # åºåˆ—å¹³å‡ log prob
    seq_lengths = mask.sum(dim=1, keepdim=True).clamp_min(1e-8)
    ref_log_probs = (ref_log_probs * mask).sum(dim=1) / seq_lengths.squeeze()
    policy_log_probs = (policy_log_probs * mask).sum(dim=1) / seq_lengths.squeeze()
    
    # åˆ†ç¦» chosen å’Œ rejected
    batch_size = ref_log_probs.shape[0]
    chosen_ref = ref_log_probs[:batch_size // 2]
    reject_ref = ref_log_probs[batch_size // 2:]
    chosen_pol = policy_log_probs[:batch_size // 2]
    reject_pol = policy_log_probs[batch_size // 2:]
    
    # DPO æ ¸å¿ƒå…¬å¼
    # Ï€(yâº) - Ï€(yâ»): ç­–ç•¥æ¨¡å‹çš„æ¦‚ç‡å·®
    # ref(yâº) - ref(yâ»): å‚è€ƒæ¨¡å‹çš„æ¦‚ç‡å·®
    pi_logratios = chosen_pol - reject_pol
    ref_logratios = chosen_ref - reject_ref
    logits = pi_logratios - ref_logratios
    
    # -log(sigmoid(Î² * logit))
    loss = -F.logsigmoid(beta * logits)
    return loss.mean()
```

**é¢è¯•è¦ç‚¹**ï¼š
- DPO vs PPOï¼šæ— éœ€å¥–åŠ±æ¨¡å‹ã€è®­ç»ƒæ›´ç¨³å®š
- å…¬å¼æ¨å¯¼ï¼šä» KL æ•£åº¦ + Bradley-Terry æ¨¡å‹æ¨å¯¼è€Œæ¥
- Reference Model ä½œç”¨ï¼šé˜²æ­¢æ¨¡å‹åç¦» SFT æ¨¡å‹å¤ªè¿œ

### 4.3 PPO (Proximal Policy Optimization)

#### 4.3.1 PPO ç®—æ³•æ¶æ„

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
flowchart TB
    subgraph "ğŸ­ Actor Model" ["<b>ğŸ­ Actor Model</b><br/>ç­–ç•¥æ¨¡å‹"]
        A1["ğŸ“¥ è¾“å…¥: prompt"] --> A2["ğŸ—ï¸ Generate<br/>ç”Ÿæˆå›å¤"]
        A2 --> A3["ğŸ“Š è®¡ç®— logÏ€(a|s)"]
        A3 --> A4["ğŸ“‰ PPO Clip Loss"]
    end
    
    subgraph "âª Old Actor" ["<b>âª Old Actor</b><br/>æ—§ç­–ç•¥"]
        B1["â±ï¸ æ¯éš” N æ­¥æ›´æ–°"] --> B2["ğŸ’¾ è®°å½•æ—§ç­–ç•¥"]
    end
    
    subgraph "ğŸ“ˆ Critic Model" ["<b>ğŸ“ˆ Critic Model</b><br/>ä»·å€¼æ¨¡å‹"]
        C1["ğŸ“Š Value Function"] --> C2["ğŸ“‰ è®¡ç®— Advantages"]
    end
    
    subgraph "ğŸ“ Reference Model" ["<b>ğŸ“ Reference Model</b><br/>å‚è€ƒæ¨¡å‹"]
        D1["â„ï¸ å†»ç»“çš„ SFT æ¨¡å‹"] --> D2["ğŸ“Š KL æ•£åº¦æƒ©ç½š"]
    end
    
    subgraph "ğŸ† Reward Model" ["<b>ğŸ† Reward Model</b><br/>å¥–åŠ±æ¨¡å‹"]
        E1["ğŸ“Š å¤–éƒ¨å¥–åŠ±"] --> E2["ğŸ“ˆ å¥–åŠ±åˆ†æ•°"]
    end
    
    A4 --> F["ğŸ”¢ <b>Total Loss</b><br/>æ€»æŸå¤±"]
    C2 --> F
    D2 --> F
    
    F --> G["â¬…ï¸ åå‘ä¼ æ’­"]
    
    style A1 fill:#e3f2fd stroke:#1565c0 stroke-width:1px
    style A2 fill:#bbdefb stroke:#1565c0 stroke-width:1px
    style A3 fill:#90caf9 stroke:#1565c0 stroke-width:1px
    style A4 fill:#64b5f6 stroke:#0d47a1 stroke-width:2px
    style B1 fill:#fff3e0 stroke:#e65100 stroke-width:1px
    style B2 fill:#ffe0b2 stroke:#e65100 stroke-width:1px
    style C1 fill:#e8f5e9 stroke:#2e7d32 stroke-width:1px
    style C2 fill:#a5d6a7 stroke:#2e7d32 stroke-width:1px
    style D1 fill:#f3e5f5 stroke:#7b1fa2 stroke-width:1px
    style D2 fill:#ce93d8 stroke:#7b1fa2 stroke-width:1px
    style E1 fill:#ffebee stroke:#c62828 stroke-width:1px
    style E2 fill:#ef9a9a stroke:#c62828 stroke-width:1px
    style F fill:#ffd54f stroke:#f9a825 stroke-width:3px
    style G fill:#64b5f6 stroke:#0d47a1 stroke-width:2px
```

#### 4.3.2 PPO æ ¸å¿ƒä»£ç 

```python
def ppo_train_step(batch, actor_model, old_actor_model, ref_model, critic_model):
    prompts = batch["prompt"]
    
    # 1. ç”Ÿæˆ responses
    gen_out = actor_model.generate(
        input_ids=enc.input_ids,
        attention_mask=enc.attention_mask,
        max_new_tokens=args.max_gen_len,
        do_sample=True,
        temperature=0.8
    )
    
    # 2. è®¡ç®—å¥–åŠ±
    responses_text = decode_responses(gen_out, prompt_lengths)
    rewards = reward_model(responses_text)
    
    # 3. è®¡ç®— advantages
    values = critic_model(gen_out)[:, -1]
    advantages = rewards - values.detach()
    
    # 4. è®¡ç®—ç­–ç•¥æŸå¤± (PPO Clip)
    logits = actor_model(gen_out).logits[:, :-1]
    logp_tokens = get_token_logps(logits, labels)
    actor_logp = (logp_tokens * final_mask).sum(dim=1)
    
    with torch.no_grad():
        old_logits = old_actor_model(gen_out).logits[:, :-1]
        old_logp = get_token_logps(old_logits, labels)
        old_logp = (old_logp * final_mask).sum(dim=1)
    
    # PPO Clip å…¬å¼
    ratio = torch.exp(actor_logp - old_logp)
    surr1 = ratio * advantages
    surr2 = torch.clamp(ratio, 1.0 - args.clip_epsilon, 1.0 + args.clip_epsilon) * advantages
    policy_loss = -torch.min(surr1, surr2).mean()
    
    # 5. ä»·å€¼æŸå¤±å’Œ KL æŸå¤±
    value_loss = F.mse_loss(values, rewards)
    kl_ref = (actor_logp - ref_logp).mean()
    
    # æ€»æŸå¤±
    loss = policy_loss + args.vf_coef * value_loss + args.kl_coef * kl_ref
    return loss
```

**é¢è¯•è¦ç‚¹**ï¼š
- PPO Clip å…¬å¼ï¼šé™åˆ¶ç­–ç•¥æ›´æ–°å¹…åº¦ï¼Œé˜²æ­¢å´©æºƒ
- KL æ•£åº¦æƒ©ç½šï¼šé˜²æ­¢ç­–ç•¥åç¦»å‚è€ƒæ¨¡å‹å¤ªè¿œ
- Advantages è®¡ç®—ï¼šR - V(s)ï¼Œè¡¡é‡åŠ¨ä½œçš„ç›¸å¯¹å¥½å

### 4.4 GRPO (Group Relative Policy Optimization)

#### 4.4.1 GRPO æ ¸å¿ƒæ€æƒ³

GRPO ç›¸å¯¹äº PPO çš„æ”¹è¿›ï¼šä½¿ç”¨ç»„å†…ç›¸å¯¹å¥–åŠ±ï¼Œæ— éœ€ Critic æ¨¡å‹ã€‚

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
flowchart LR
    A[ğŸ“ <b>Prompt</b>] --> B["ğŸ¯ ç”Ÿæˆ N ä¸ª<br/>responses (N=8)"]
    B --> C1["ğŸ“‹ Response 1"]
    B --> C2["ğŸ“‹ Response 2"]
    B --> C3["ğŸ“‹ Response 3"]
    B --> C4["ğŸ“‹ Response 4"]
    B --> C5["... Response N"]
    
    C1 --> D[ğŸ“Š <b>è®¡ç®—å¥–åŠ±</b><br/>Reward Model]
    C2 --> D
    C3 --> D
    C4 --> D
    C5 --> D
    
    D --> E1["â­ râ‚"]
    D --> E2["â­ râ‚‚"]
    D --> E3["â­ râ‚ƒ"]
    D --> E4["â­ râ‚„"]
    D --> E5["â­ râ‚™"]
    
    E1 --> F["ğŸ“ˆ <b>å½’ä¸€åŒ–</b><br/>Aáµ¢ = (ráµ¢ - mean) / std"]
    E2 --> F
    E3 --> F
    E4 --> F
    E5 --> F
    
    F --> G[ğŸ¯ <b>ç­–ç•¥æ¢¯åº¦æ›´æ–°</b>]
    
    style A fill:#e3f2fd stroke:#1565c0 stroke-width:2px
    style B fill:#bbdefb stroke:#1565c0 stroke-width:2px
    style C1 fill:#fff9c4 stroke:#f9a825 stroke-width:1px
    style C2 fill:#fff9c4 stroke:#f9a825 stroke-width:1px
    style C3 fill:#fff9c4 stroke:#f9a825 stroke-width:1px
    style C4 fill:#fff9c4 stroke:#f9a825 stroke-width:1px
    style C5 fill:#fff9c4 stroke:#f9a825 stroke-width:1px
    style D fill:#a5d6a7 stroke:#2e7d32 stroke-width:2px
    style F fill:#c8e6c9 stroke:#2e7d32 stroke-width:2px
    style G fill:#81c784 stroke:#2e7d32 stroke-width:2px
```

#### 4.4.2 GRPO æ ¸å¿ƒä»£ç 

```python
def grpo_train_step(prompts, model, ref_model, reward_model):
    batch_size = len(prompts)
    
    # 1. ç”Ÿæˆå¤šä¸ª responses
    outputs = model.generate(
        **prompt_inputs,
        max_new_tokens=args.max_gen_len,
        num_return_sequences=args.num_generations,  # 8ä¸ª
        do_sample=True,
        temperature=0.8
    )
    
    completions = decode_responses(outputs)
    
    # 2. è®¡ç®—å¥–åŠ±
    rewards = calculate_rewards(prompts, completions, reward_model)
    
    # 3. å¥–åŠ±å½’ä¸€åŒ– (ç»„å†…ç›¸å¯¹)
    grouped_rewards = rewards.view(-1, args.num_generations)
    mean_r = grouped_rewards.mean(dim=1).repeat_interleave(args.num_generations)
    std_r = grouped_rewards.std(dim=1).repeat_interleave(args.num_generations)
    
    # é™åˆ¶èŒƒå›´ + æ ‡å‡†å½’ä¸€åŒ–
    advantages = torch.clamp((rewards - mean_r) / (std_r + 1e-4), -10, 10)
    advantages = (advantages - advantages.mean()) / (advantages.std() + 1e-8)
    
    # 4. è®¡ç®— KL æ•£åº¦
    per_token_logps = get_per_token_logps(model, outputs)
    ref_per_token_logps = get_per_token_logps(ref_model, outputs)
    kl_div = ref_per_token_logps - per_token_logps
    per_token_kl = torch.exp(kl_div) - kl_div - 1
    
    # 5. GRPO æŸå¤±
    per_token_loss = -(
        torch.exp(per_token_logps - per_token_logps.detach()) * advantages.unsqueeze(1)
        - args.beta * per_token_kl
    )
    
    loss = ((per_token_loss * completion_mask).sum(dim=1) / 
            completion_mask.sum(dim=1)).mean()
    return loss
```

**é¢è¯•è¦ç‚¹**ï¼š
- GRPO ä¼˜åŠ¿ï¼šæ— éœ€ Critic æ¨¡å‹ï¼Œè®¡ç®—æ›´é«˜æ•ˆ
- ç»„å†…å½’ä¸€åŒ–ï¼šæ¶ˆé™¤å¥–åŠ±å°ºåº¦çš„å½±å“
- é€‚åˆåœºæ™¯ï¼šä»£ç ç”Ÿæˆã€æ•°å­¦æ¨ç†ç­‰æœ‰æ˜ç¡®æ ‡å‡†ç­”æ¡ˆçš„ä»»åŠ¡

### 4.5 SPO (Self-Play Optimization)

#### 4.5.1 è‡ªå¯¹å¼ˆæ€æƒ³

SPO çš„æ ¸å¿ƒæ˜¯ä½¿ç”¨è‡ªé€‚åº”ä»·å€¼è¿½è¸ªå™¨æ›¿ä»£å›ºå®šå¥–åŠ±æ¨¡å‹ã€‚

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
flowchart TD
    A[<b>ğŸ”§ AutoAdaptive<br/>Value Tracker</b>] --> B[<b>Ï è‡ªé€‚åº”ç³»æ•°</b><br/>Adaptive Coef]
    A --> C[<b>Î±, Î² Beta å‚æ•°</b><br/>Beta Parameters]
    
    B --> D["ğŸ§® åŸºäº KL è°ƒæ•´<br/>KL â†‘ â†’ Ï â†“"]
    D --> E["âš–ï¸ å‡å°‘ç­–ç•¥æ›´æ–°<br/>å¹…åº¦"]
    
    C --> F["ğŸ“Š è¿½è¸ªå¥–åŠ±åˆ†å¸ƒ<br/>Track Reward Dist"]
    F --> G["ğŸ“ˆ Baselines = Î±/(Î±+Î²)"]
    G --> H["ğŸ“‰ Advantages =<br/>R - Baseline"]
    
    style A fill:#e1bee7 stroke:#7b1fa2 stroke-width:3px
    style B fill:#ce93d8 stroke:#7b1fa2 stroke-width:2px
    style C fill:#ba68c8 stroke:#7b1fa2 stroke-width:2px
    style D fill:#ab47bc stroke:#7b1fa2 stroke-width:1px
    style E fill:#9c27b0 stroke:#7b1fa2 stroke-width:1px
    style F fill:#8e24aa stroke:#7b1fa2 stroke-width:1px
    style G fill:#7b1fa2 stroke:#6a1b9a stroke-width:2px
    style H fill:#6a1b9a stroke:#4a148c stroke-width:2px
```

#### 4.5.2 è‡ªé€‚åº”ä»·å€¼è¿½è¸ªå™¨

```python
class AutoAdaptiveValueTracker:
    def __init__(self, rho_mode='kl', rho_const=0.9, D_half=0.06):
        self.rho_mode = rho_mode      # 'constant' æˆ– 'kl'
        self.rho_const = rho_const    # å¸¸æ•° Ï
        self.D_half = D_half          # KL åŠè¡°æœŸå‚æ•°
        self.alpha = 0.5              # Beta åˆ†å¸ƒå‚æ•°
        self.beta = 0.5
    
    def compute_rho(self, cur_mean_logprob):
        if self.rho_mode == 'constant':
            return self.rho_const
        
        if self.old_mean_logprob is None:
            return self.rho_const
        
        # åŸºäº KL æ•£åº¦è‡ªé€‚åº”è°ƒæ•´ Ï
        kl = abs(self.old_mean_logprob - cur_mean_logprob)
        rho = 2 ** (-kl / self.D_half)  # æŒ‡æ•°è¡°å‡
        return max(min(rho, 0.96), 0.5)  # è£å‰ªèŒƒå›´
    
    def update(self, rewards, cur_logprobs, response_masks):
        # è®¡ç®—å½“å‰å¹³å‡ logprob
        mean_logprob = ((cur_logprobs * response_masks).sum() / 
                        response_masks.sum()).item()
        
        # è‡ªé€‚åº”è°ƒæ•´ Ï
        rho = self.compute_rho(mean_logprob)
        self.old_mean_logprob = mean_logprob
        
        # å½’ä¸€åŒ–å¥–åŠ±åˆ° [0, 1]
        scale = 3.0
        normalized_rewards = (rewards + scale) / (2 * scale)
        avg_normalized_reward = normalized_rewards.mean().item()
        
        # æŒ‡æ•°ç§»åŠ¨å¹³å‡æ›´æ–° Beta åˆ†å¸ƒå‚æ•°
        self.alpha = rho * self.alpha + avg_normalized_reward
        self.beta = rho * self.beta + (1 - avg_normalized_reward)
        
        return rho
    
    def get_baselines(self, batch_size):
        # Beta åˆ†å¸ƒå‡å€¼ä½œä¸ºåŸºçº¿
        baseline = self.alpha / (self.alpha + self.beta)
        return torch.full((batch_size,), baseline, dtype=torch.float32)
```

**é¢è¯•è¦ç‚¹**ï¼š
- SPO ä¼˜åŠ¿ï¼šè‡ªé€‚åº”è°ƒæ•´ï¼Œæ— éœ€æ‰‹åŠ¨è°ƒå‚
- Ï å‚æ•°ä½œç”¨ï¼šå¹³è¡¡æ¢ç´¢ä¸åˆ©ç”¨
- Beta åˆ†å¸ƒåŸºçº¿ï¼šæ¯”å›ºå®šå€¼æ›´é²æ£’

### 4.6 å¯¹æ¯”æ€»ç»“

| ç®—æ³• | å¥–åŠ±æ¨¡å‹ | Critic æ¨¡å‹ | é€‚ç”¨åœºæ™¯ | å¤æ‚åº¦ |
|------|---------|-------------|---------|--------|
| **DPO** | âŒ | âŒ | åå¥½æ•°æ®å……è¶³ | â­ ä½ |
| **PPO** | âœ… | âœ… | é€šç”¨åœºæ™¯ | â­â­â­ é«˜ |
| **GRPO** | âœ… | âŒ | ä»£ç /æ•°å­¦æ¨ç† | â­â­ ä¸­ |
| **SPO** | âŒ | âŒ | è‡ªé€‚åº”åœºæ™¯ | â­â­ ä¸­ |

---

## 5. çŸ¥è¯†è’¸é¦ç®—æ³•

### 5.1 çŸ¥è¯†è’¸é¦å…¨æ™¯

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
graph TD
    A[ğŸ“š <b>çŸ¥è¯†è’¸é¦</b><br/>Knowledge Distillation] --> B[ğŸ“Š <b>æ ‡å‡†è’¸é¦</b><br/>Standard Distill]
    A --> C[ğŸ§  <b>æ¨ç†è’¸é¦</b><br/>Reasoning Distill]
    
    B --> B1["ğŸ‘¨â€ğŸ« Teacher<br/>MiniMind-768"]
    B --> B2["ğŸ‘¨â€ğŸ“ Student<br/>MiniMind-512"]
    B --> B3["ğŸ¯ Logits å¯¹é½"]
    
    C --> C1["âš¡ å¢å¼º CoT<br/>æƒé‡"]
    C --> C2["ğŸ·ï¸ ç‰¹æ®Š Token<br/>10x æƒé‡"]
    
    style A fill:#3d5a80 stroke:#293241 stroke-width:3px
    style B fill:#98c1d9 stroke:#293241 stroke-width:2px
    style C fill:#98c1d9 stroke:#293241 stroke-width:2px
    style B1 fill:#bbdefb stroke:#1565c0 stroke-width:1px
    style B2 fill:#a5d6a7 stroke:#2e7d32 stroke-width:1px
    style B3 fill:#fff9c4 stroke:#f9a825 stroke-width:1px
    style C1 fill:#f3e5f5 stroke:#7b1fa2 stroke-width:1px
    style C2 fill:#ffecb3 stroke:#ff8f00 stroke-width:1px
```

### 5.2 æ ‡å‡†çŸ¥è¯†è’¸é¦

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
flowchart LR
    subgraph "ğŸ‘¨â€ğŸ« Teacher" ["<b>ğŸ‘¨â€ğŸ« Teacher</b><br/>MiniMind-768"]
        T["ğŸ“¦ å†»ç»“æ¨¡å‹"] --> T1["ğŸ“Š Logits è¾“å‡º"]
    end
    
    subgraph "ğŸ‘¨â€ğŸ“ Student" ["<b>ğŸ‘¨â€ğŸ“ Student</b><br/>MiniMind-512"]
        S["ğŸ“¦ å¯è®­ç»ƒæ¨¡å‹"] --> S1["ğŸ“Š Logits è¾“å‡º"]
    end
    
    subgraph "ğŸ“‰ Loss" ["<b>ğŸ“‰ Loss</b>"]
        L1["ğŸ“ CE Loss<br/>GT ç›‘ç£"] --> L3["ğŸ”¢ <b>Total Loss</b>"]
        L2["ğŸ“Š KL Loss<br/>Logits å¯¹é½"] --> L3
    end
    
    S1 --> L2
    T1 --> L2
    
    style T fill:#bbdefb stroke:#1565c0 stroke-width:2px
    style T1 fill:#90caf9 stroke:#1565c0 stroke-width:1px
    style S fill:#a5d6a7 stroke:#2e7d32 stroke-width:2px
    style S1 fill:#81c784 stroke:#2e7d32 stroke-width:1px
    style L1 fill:#fff9c4 stroke:#f9a825 stroke-width:1px
    style L2 fill:#fff3e0 stroke:#e65100 stroke-width:1px
    style L3 fill:#ffd54f stroke:#f9a825 stroke-width:3px
```

```python
def distillation_loss(student_logits, teacher_logits, temperature=1.0):
    # Teacher æ¦‚ç‡åˆ†å¸ƒ
    with torch.no_grad():
        teacher_probs = F.softmax(teacher_logits / temperature, dim=-1)
    
    # Student å¯¹æ•°æ¦‚ç‡
    student_log_probs = F.log_softmax(student_logits / temperature, dim=-1)
    
    # KL æ•£åº¦: KL(P||Q) = P * log(P/Q)
    kl = F.kl_div(
        student_log_probs,
        teacher_probs,
        reduction='batchmean',
        log_target=False
    )
    
    # æ¸©åº¦å¹³æ–¹æ¢å¤
    return (temperature ** 2) * kl

# æ€»æŸå¤±
total_loss = alpha * ce_loss + (1 - alpha) * kl_loss
```

### 5.3 æ¨ç†è’¸é¦

é’ˆå¯¹ `<thought>` ç­‰ç‰¹æ®Š token å¢åŠ  10 å€æŸå¤±æƒé‡ï¼š

```python
# ç‰¹æ®Š token IDs
start_of_think_ids = tokenizer('<thought>').input_ids
end_of_think_ids = tokenizer('</thought>').input_ids
start_of_answer_ids = tokenizer('<answer>').input_ids
end_of_answer_ids = tokenizer('</answer>').input_ids

# ç”ŸæˆæŸå¤±æ©ç 
sp_ids = torch.isin(
    Y.view(-1),
    torch.tensor(start_of_think_ids + end_of_think_ids + 
                 start_of_answer_ids + end_of_answer_ids).to(device)
)
loss_mask[sp_ids] = 10  # 10å€æƒé‡

# æœ€ç»ˆæŸå¤±è®¡ç®—
final_loss = (per_token_loss * loss_mask.view(-1)).sum() / loss_mask.sum()
```

---

## 6. é¢è¯•é«˜é¢‘é—®é¢˜æ±‡æ€»

### 6.1 æ¨¡å‹æ¶æ„ç±»é—®é¢˜

**Q1: RoPE ç›¸æ¯”å…¶ä»–ä½ç½®ç¼–ç çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ**

A:
1. **å¯å¤–æ¨æ€§**ï¼šæ”¯æŒæ›´é•¿ä¸Šä¸‹æ–‡ï¼ŒYaRN å¯æ‰©å±•è‡³ 4 å€+
2. **è®¡ç®—é«˜æ•ˆ**ï¼šåªéœ€é¢„è®¡ç®—é¢‘ç‡ï¼Œæ— éœ€é¢å¤–å‚æ•°
3. **ç›¸å¯¹ä½ç½®æ„ŸçŸ¥**ï¼šè‡ªç„¶ä¿ç•™ç›¸å¯¹ä½ç½®ä¿¡æ¯
4. **æ•°å€¼ç¨³å®š**ï¼šæ²¡æœ‰æº¢å‡ºé£é™©

**Q2: GQA å’Œ MHA çš„åŒºåˆ«ï¼Ÿä¸ºä»€ä¹ˆé€‰æ‹© GQAï¼Ÿ**

A:
- MHAï¼šQ/K/V å¤´æ•°ç›¸åŒï¼Œæ¯ä¸ªå¤´ç‹¬ç«‹
- GQAï¼šQ å¤´æ•°æ˜¯ KV å¤´æ•°çš„ N å€ï¼ŒKV å¤´è¢«å¤ç”¨
- ä¼˜åŠ¿ï¼šå‡å°‘ 50%+ KV cache å†…å­˜ï¼ŒåŠ é€Ÿæ¨ç†
- é€‚ç”¨ï¼šæ¨ç†åœºæ™¯ï¼ŒQwen2/Llama3 é‡‡ç”¨

**Q3: MoE ä¸ºä»€ä¹ˆèƒ½ä»¥è¾ƒå°‘å‚æ•°è¾¾åˆ°è¾ƒå¤§æ¨¡å‹æ•ˆæœï¼Ÿ**

A:
1. **ç¨€ç–æ¿€æ´»**ï¼šæ¯ä¸ª token åªæ¿€æ´» 2-4 ä¸ªä¸“å®¶
2. **è´Ÿè½½å‡è¡¡**ï¼šå¤šä¸“å®¶åˆ†æ‹…ä¸åŒçŸ¥è¯†
3. **å‚æ•°é«˜æ•ˆ**ï¼šæ€»å‚æ•°é‡å¤§ä½†æ¨ç†è®¡ç®—é‡å°
4. **çŸ¥è¯†ä¸“ä¸šåŒ–**ï¼šä¸åŒä¸“å®¶å­¦ä¹ ä¸åŒå­ä»»åŠ¡

### 6.2 è®­ç»ƒç®—æ³•ç±»é—®é¢˜

**Q4: DPO ç›¸æ¯” PPO çš„ä¼˜åŠ¿å’ŒåŠ£åŠ¿ï¼Ÿ**

A:
- **ä¼˜åŠ¿**ï¼šæ— éœ€å¥–åŠ±æ¨¡å‹ã€è®­ç»ƒæ›´ç¨³å®šã€è¶…å‚å°‘
- **åŠ£åŠ¿**ï¼šéœ€è¦é«˜è´¨é‡åå¥½å¯¹ã€æ•°æ®æˆæœ¬é«˜
- **é€‚ç”¨**ï¼šåå¥½æ•°æ®å……è¶³ã€è¿½æ±‚ç¨³å®šæ€§çš„åœºæ™¯

**Q5: PPO ä¸­ Clip å…¬å¼çš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ**

A:
$$\min(r_t(\theta)\hat{A}_t, \text{clip}(r_t(\theta), 1-\epsilon, 1+\epsilon)\hat{A}_t)$$

- é™åˆ¶ç­–ç•¥æ›´æ–°å¹…åº¦ï¼Œé˜²æ­¢ç­–ç•¥å´©æºƒ
- å½“ advantage ä¸ºæ­£æ—¶ï¼Œé™åˆ¶æ­£å‘æ›´æ–°
- å½“ advantage ä¸ºè´Ÿæ—¶ï¼Œé™åˆ¶è´Ÿå‘æ›´æ–°

**Q6: GRPO ä¸ºä»€ä¹ˆä¸éœ€è¦ Critic æ¨¡å‹ï¼Ÿ**

A:
- GRPO ä½¿ç”¨ç»„å†…ç›¸å¯¹å¥–åŠ±ä»£æ›¿ç»å¯¹å€¼
- $A_i = (r_i - \text{mean}(r)) / \text{std}(r)$
- ç›¸å¯¹å€¼å¤©ç„¶å…·æœ‰baselineæ•ˆæœ
- ç®€åŒ–è®­ç»ƒæµç¨‹ï¼Œé™ä½è®¡ç®—å¼€é”€

### 6.3 å·¥ç¨‹å®è·µç±»é—®é¢˜

**Q7: æ··åˆç²¾åº¦è®­ç»ƒéœ€è¦æ³¨æ„ä»€ä¹ˆï¼Ÿ**

A:
1. **Loss Scale**ï¼šé˜²æ­¢ FP16 ä¸‹æº¢
2. **Dynamic Loss Scaling**ï¼šè‡ªåŠ¨è°ƒæ•´ scale
3. **è£å‰ªæ¢¯åº¦**ï¼šé˜²æ­¢ FP16 æº¢å‡º
4. **ç‰¹å®šå±‚ä¿æŒ FP32**ï¼šå¦‚ LayerNorm

**Q8: å¦‚ä½•å®ç°é«˜æ•ˆçš„è®­ç»ƒæ£€æŸ¥ç‚¹æ¢å¤ï¼Ÿ**

A:
```python
def load_checkpoint(model, optimizer, scaler, path):
    ckp = torch.load(path, map_location=device)
    
    # æ¢å¤æ¨¡å‹æƒé‡
    model.load_state_dict(ckp['model'])
    
    # æ¢å¤ä¼˜åŒ–å™¨çŠ¶æ€
    optimizer.load_state_dict(ckp['optimizer'])
    
    # æ¢å¤ AMP çŠ¶æ€
    scaler.load_state_dict(ckp['scaler'])
    
    # æ¢å¤è®­ç»ƒçŠ¶æ€
    start_step = ckp['step']
    return start_step
```

**Q9: Flash Attention çš„åŸç†å’Œä¼˜åŠ¿ï¼Ÿ**

A:
- **åŸç†**ï¼šåˆ†å—è®¡ç®— + åœ¨çº¿ softmaxï¼Œå°† $O(N^2)$ é™è‡³ $O(N)$
- **ä¼˜åŠ¿**ï¼š
  - å‡å°‘æ˜¾å­˜å ç”¨ï¼ˆä» $O(N^2)$ åˆ° $O(N)$ï¼‰
  - æé«˜è®¡ç®—åå
  - åˆ©ç”¨ GPU å†…å­˜å±‚æ¬¡ç»“æ„

---

## 7. æ ¸å¿ƒä»£ç æ·±åº¦è§£æ

### 7.1 å®Œæ•´æ¨¡å‹å®šä¹‰

```python
class MiniMindModel(nn.Module):
    def __init__(self, config: MiniMindConfig):
        self.hidden_size = config.hidden_size
        self.num_layers = config.num_hidden_layers
        self.num_attention_heads = config.num_attention_heads
        self.use_moe = config.use_moe
        
        # è¯åµŒå…¥
        self.embed_tokens = nn.Embedding(config.vocab_size, config.hidden_size)
        
        # Transformer å±‚
        self.layers = nn.ModuleList([
            MiniMindBlock(config) for _ in range(config.num_hidden_layers)
        ])
        
        # è¾“å‡ºå½’ä¸€åŒ–
        self.norm = RMSNorm(config.hidden_size, eps=config.rms_norm_eps)
        
        # é¢„è®¡ç®— RoPE
        self.freqs_cos, self.freqs_sin = precompute_freqs_cis(
            config.hidden_size // config.num_attention_heads,
            config.max_position_embeddings * 2,
            config.rope_theta,
            getattr(config, 'rope_scaling', None)
        )
    
    def forward(self, input_ids: torch.Tensor, **kwargs):
        # è¯åµŒå…¥
        hidden_states = self.embed_tokens(input_ids)
        
        # ä½ç½®ç¼–ç 
        seq_len = input_ids.shape[1]
        cos = self.freqs_cos[:seq_len]
        sin = self.freqs_sin[:seq_len]
        
        # Transformer å‰å‘
        for layer in self.layers:
            hidden_states = layer(hidden_states, cos, sin, **kwargs)
        
        # è¾“å‡º
        hidden_states = self.norm(hidden_states)
        return BaseModelOutputWithPast(last_hidden_state=hidden_states)
```

### 7.2 MiniMindBlock å®ç°

```python
class MiniMindBlock(nn.Module):
    def __init__(self, config: MiniMindConfig):
        super().__init__()
        self.hidden_size = config.hidden_size
        self.attention = Attention(config)
        self.feed_forward = FeedForward(config)
        self.attention_norm = RMSNorm(config.hidden_size, eps=config.rms_norm_eps)
        self.ffn_norm = RMSNorm(config.hidden_size, eps=config.rms_norm_eps)
        self.dropout = nn.Dropout(config.dropout)
    
    def forward(self, x, freqs_cos, freqs_sin, **kwargs):
        # Pre-LN ç»“æ„
        h = x + self.attention(self.attention_norm(x), freqs_cos, freqs_sin, **kwargs)
        out = h + self.feed_forward(self.ffn_norm(h))
        return out
```

### 7.3 KV Cache æ¨ç†

```python
def generate_with_cache(
    model,
    input_ids,
    max_new_tokens=100,
    temperature=1.0,
    top_p=0.9
):
    batch_size = input_ids.shape[0]
    past_key_values = None
    
    for _ in range(max_new_tokens):
        outputs = model(
            input_ids,
            past_key_values=past_key_values,
            use_cache=True
        )
        
        logits = outputs.logits[:, -1, :]
        past_key_values = outputs.past_key_values
        
        # é‡‡æ ·
        probs = F.softmax(logits / temperature, dim=-1)
        next_token = torch.multinomial(probs, 1)
        input_ids = torch.cat([input_ids, next_token], dim=-1)
    
    return input_ids
```

### 7.4 è®­ç»ƒæµç¨‹æ€»ç»“

```mermaid
---
config:
  theme: base
  themeVariables:
    fontFamily: "Georgia, serif"
---
flowchart TD
    A[ğŸ”§ <b>åˆå§‹åŒ–æ¨¡å‹</b>] --> B[âš™ï¸ <b>åˆå§‹åŒ–ä¼˜åŒ–å™¨</b>]
    B --> C[ğŸ”¢ <b>AMP Scaler</b><br/>æ··åˆç²¾åº¦]
    C --> D[ğŸ’¾ <b>åŠ è½½æ£€æŸ¥ç‚¹</b><br/>Checkpoint]
    D --> E{ğŸ”„ <b>è®­ç»ƒå¾ªç¯</b><br/>Training Loop}
    
    E --> F[ğŸ“¥ <b>è·å–æ•°æ®</b>]
    F --> G[ğŸ”„ <b>æ··åˆç²¾åº¦å‰å‘</b>]
    G --> H[ğŸ“Š <b>è®¡ç®—æŸå¤±</b>]
    H --> I[â¬…ï¸ <b>åå‘ä¼ æ’­</b>]
    I --> J[âœ‚ï¸ <b>æ¢¯åº¦è£å‰ª</b>]
    J --> K[âœ… <b>ä¼˜åŒ–å™¨æ›´æ–°</b>]
    K --> L{ğŸ’¾ <b>æ£€æŸ¥ä¿å­˜</b>}
    L -->|Yes| M[ğŸ’¾ <b>ä¿å­˜æ£€æŸ¥ç‚¹</b>]
    M --> E
    L -->|No| E
    
    style A fill:#3d5a80 stroke:#293241 stroke-width:2px
    style B fill:#98c1d9 stroke:#293241 stroke-width:2px
    style C fill:#98c1d9 stroke:#293241 stroke-width:2px
    style D fill:#bbdefb stroke:#1565c0 stroke-width:2px
    style E fill:#a5d6a7 stroke:#2e7d32 stroke-width:3px
    style F fill:#fff9c4 stroke:#f9a825 stroke-width:1px
    style G fill:#fff3e0 stroke:#e65100 stroke-width:1px
    style H fill:#fcf6bd stroke:#d0a04b stroke-width:1px
    style I fill:#ffebee stroke:#c62828 stroke-width:1px
    style J fill:#e8f5e9 stroke:#2e7d32 stroke-width:1px
    style K fill:#c8e6c9 stroke:#2e7d32 stroke-width:1px
    style M fill:#81c784 stroke:#2e7d32 stroke-width:2px
```

---

## é™„å½•ï¼šMiniMind æ¨¡å‹è§„æ¨¡

| æ¨¡å‹ | å‚æ•°é‡ | éšè—å±‚ | å±‚æ•° | KV å¤´ | ä¸“å®¶æ•° |
|------|--------|--------|------|-------|--------|
| MiniMind-Small | 25.8M | 512 | 8 | 2 | - |
| MiniMind-MoE | 145M | 640 | 8 | 2 | 4 |
| MiniMind-Base | 104M | 768 | 16 | 2 | - |

---

## ğŸ¨ è®¾è®¡è¯´æ˜

æœ¬æ•™ç¨‹é‡‡ç”¨ä»¥ä¸‹è®¾è®¡åŸåˆ™ï¼š

### é…è‰²æ–¹æ¡ˆ
- **è“è‰²ç³»** (3d5a80, 98c1d9, e3f2fd): æ¨¡å‹æ¶æ„ç›¸å…³
- **ç»¿è‰²ç³»** (a5d6a7, c8e6c9): é¢„è®­ç»ƒã€ä¼˜åŒ–ç›¸å…³
- **ç´«è‰²ç³»** (e1bee7, 7b1fa2): SPOã€æ³¨æ„åŠ›æœºåˆ¶
- **é»„è‰²ç³»** (fff9c4, fcf6bd): æŸå¤±å‡½æ•°ã€å¥–åŠ±
- **ç²‰è‰²ç³»** (ff99c8, c9184a): å¯¹é½ç®—æ³•ã€PPO
- **æ©™è‰²ç³»** (fff3e0, e65100): æŸå¤±æ©ç ã€æ•°æ®å¤„ç†

### è§†è§‰å±‚æ¬¡
- **ä¸€çº§èŠ‚ç‚¹**: æ·±è‰²è¾¹æ¡† + å¡«å……
- **äºŒçº§èŠ‚ç‚¹**: ä¸­ç­‰è¾¹æ¡† + æµ…è‰²å¡«å……
- **ä¸‰çº§èŠ‚ç‚¹**: ç»†è¾¹æ¡† + ææµ…å¡«å……

### å­—ä½“
- ä¼˜å…ˆä½¿ç”¨ Georgia è¡¬çº¿å­—ä½“ï¼Œç¬¦åˆå­¦æœ¯é¡¶åˆŠé£æ ¼

---

> **é¢è¯•å»ºè®®**ï¼š
> 1. ç†è§£æ¯ä¸ªç®—æ³•çš„**æ ¸å¿ƒç›´è§‰**ï¼Œè€Œä¸åªæ˜¯å…¬å¼
> 2. æŒæ¡**ä»£ç å®ç°ç»†èŠ‚**ï¼Œè¿™æ˜¯åŠ åˆ†é¡¹
> 3. èƒ½å¤Ÿ**å¯¹æ¯”ä¸åŒç®—æ³•**çš„ä¼˜åŠ£å’Œé€‚ç”¨åœºæ™¯
> 4. äº†è§£**å·¥ç¨‹å®è·µç»éªŒ**ï¼Œå¦‚æ··åˆç²¾åº¦ã€æ¢¯åº¦è£å‰ª